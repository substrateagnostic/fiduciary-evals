[project]
name = "fiduciary-evals"
version = "0.1.0"
description = "Safety benchmarks for fiduciary duty preservation in AI agents"
readme = "README.md"
requires-python = ">=3.10"
license = { text = "MIT" }
authors = [
    { name = "Alex Galle-From", email = "agallefrom@gmail.com" }
]
keywords = ["ai-safety", "benchmarks", "fiduciary", "alignment", "llm"]

dependencies = [
    "anthropic>=0.40.0",
    "openai>=1.50.0",
    "google-generativeai>=0.8.0",
    "pydantic>=2.0.0",
    "rich>=13.0.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "ruff>=0.6.0",
]

[project.scripts]
fiduciary-evals = "evals.runner:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "W"]
